Epoch,Learning Rate,Training Loss,Validation Accuracy
1,0.0001,1.5249660209649138,90.9400405883789
2,0.0001,1.5169744220458798,91.12970733642578
3,0.0001,1.501336036870877,90.81151580810547
4,0.0001,1.612356049526069,90.22947692871094
5,0.0001,1.5877879098471668,90.87812805175781
6,0.0001,1.7093290910124779,89.78828430175781
7,0.0001,1.5329144410789013,90.70524597167969
8,0.0001,1.5547228817724519,90.96459197998047
9,0.0001,1.4366632509562705,91.16414642333984
10,0.0001,1.4286602718962564,91.01219940185547
11,0.0001,1.4724145010113716,91.28785705566406
12,0.0001,1.6216000660012166,91.10713958740234
13,0.0001,1.4520089789811108,91.34776306152344
14,0.0001,1.3811384602967236,91.14656066894531
15,0.0001,1.370838464755151,91.20475769042969
16,0.0001,1.3593505511267319,90.62150573730469
17,0.0001,1.3668501544743776,91.29632568359375
18,0.0001,1.4952545921421714,91.01667785644531
19,0.0001,1.4326289031240675,91.31768035888672
20,0.0001,1.3990576376931534,89.67078399658203
21,0.0001,1.3950230965597763,91.48558044433594
22,0.0001,1.3773811142891645,91.42221069335938
23,0.0001,1.3189058295554585,91.1683349609375
24,0.0001,1.3189039489047394,91.27194213867188
25,0.0001,1.3043412586881056,90.8993148803711
26,0.0001,1.323632288724184,91.19537353515625
27,0.0001,1.307677419235309,91.1679916381836
28,0.0001,1.28394366780089,90.91136169433594
29,0.0001,1.2812606905483537,91.03231811523438
30,0.0001,1.2901307940483093,91.05792236328125
31,0.0001,1.2752525876793597,91.3354263305664
32,0.0001,1.289608105810152,91.18731689453125
33,0.0001,1.4307516523533397,91.23211669921875
34,0.0001,1.3327481732186344,91.29559326171875
35,0.0001,1.6694664019677374,89.93959045410156
36,0.0001,1.4562486453602712,90.51428985595703
37,0.0001,1.2947390125029616,91.16452026367188
38,0.0001,1.2364701338940196,91.05514526367188
39,0.0001,1.242467475641105,91.29290771484375
40,0.0001,1.3266042922106054,90.56584930419922
